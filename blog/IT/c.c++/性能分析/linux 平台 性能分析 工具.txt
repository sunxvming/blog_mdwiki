1. Intel VTune http://software.intel.com/en-us/intel-vtune-amplifier-xe/


大名鼎鼎的分析工具，可以直接启动一个程序来分析，


比如


$vtuneHome/amplxe-cl  -collect hotspots -duration 600 -r /apsara/save_result ./myapp para1 para2


也可以针对运行中的进程来分析，


$vtuneHome/amplxe-cl  -collect hotspots -duration 600 -r /apsara/save_result -target-pid $myapp_pid


运行结束后，就可以使用gui工具来展示结果，直观易懂，非常方便。


VTune不仅支持对热点函数(hotspots)的分析，还支持对并发、锁等待、不同类型的CPU内存访问（都是Intel自家的）、读写带宽等进行分析，功能强大。


总之，VTune唯一不足的就是收费，免费试用一个月就过期，过期了需要重新申请，比较麻烦。


gui 简单使用：


1.       首先通过file->new ->project 来创建一个project. 输入Project name和location.


2.       之后会弹出一个配置Project Properties 的对话框，选择需要profile的对象target, 在这里提供了3中Target的类型：


a.       Launch Application, 在这种target的情况下，在下面的Application中输入你要profile的应用程序，于是在后面开始profile的时候，VTune会启动这个应用程序。


b.      Attach to Process, 在种target的情况下，在下面的ProcessID中输入进程ID即可，主要针对的是已经启动的后台程序，VTune可以attach to Process对某一个时段的操作进行profile.


c.       Profile System,  在这种情况下，不需要选择target,直接对系统进程进行profile.


这3种情况和VS的debug模式很像。


3.       在配置完Project Properties之后，就可以选择new Analysis 图标，对这个project选择的target创建新的analysis. 可以针对一个project创建很多次的analysis。


4.       在创建新的analysis时，需要选择analysis的类型，我只试过HotSpots这类型的分析类型，选择类型之后，就可以点击右边的start按钮开始profile工作了。


5.       在完成profile时，点击stop按钮，就会结束profile，接着对profile的结构进行分析整理，以图表的形式展现出每个耗时的hotspot。


6.       于是程序员就可以针对hotspot，进行有针对性的优化。


 


PS：其自带的一个Get Start 帮助文档很有帮助，对于初次使用的人很有帮助。






2. OProfile http://en.wikipedia.org/wiki/OProfile


OProfile最大的好处是方便，一般OS都自带了这个工具，不用做任何准备就可以使用。


该工具设计初衷是针对事件进行采样，比如CPU时钟，L2 cache miss等，其将整个系统当做一个整体来看，对于分析kernel或者系统级别的问题比较有用，而如果用于分析个人开发的应用程序，其显得不足，主要表现在其callgraph不清晰。


比如OProfile告诉你std::find调用占了30%，如果你的程序只有几百行，那么你很快就能定位到使用std::find的地方；而如果程序有几万行，而OProfile的Callgraph很不给力，那么想知道这些std::find都是谁调用的就很困难了。


一句话，对于千行以内的程序或者很少使用stl的程序，OProfile能发挥作用；对于万行程序或者大量使用了stl的程序，OProfile不那么给力。


 


其基本的使用方法是，


opcontrol --no-vmlinux : 指示oprofile启动检测后，不记录内核模块、内核代码相关统计数据
opcontrol --init : 加载oprofile模块、oprofile驱动程序
opcontrol --start : 指示oprofile启动检测
opcontrol --dump : 指示将oprofile检测到的数据写入文件
启动你的应用程序；
opcontrol --stop


opreport -D smart -l > /tmp/report : 写入分析结果，不包括callgraph，如果需要callgraph，则使用
opreport -c -D smart -l > /tmp/report : 这一步很慢；


还可以分析源代码，会将每行代码标上所耗费CPU的比例；
opannotate -s /lib64/libc-2.4.so : 以代码的角度，针对libc-2.4.so库显示检测结果


还有一些用法，man可以看到更详细的解释；
opcontrol --reset : 清空之前检测的数据记录
opcontrol -h : 关闭oprofile进程


 


有时候opreport会报告说buffersize不够丢了一些采样点，这时候可以调整buffer size。buffer size不是以byte计数，而是以能做多少sample来计数的；分为两级，一个是总的buffer size，一个是每个cpu的buffer size，如果超过了bufer watershed就flush到磁盘文件中。如下，是修改之后的：


$sudo opcontrol --status
Daemon not running
Session-dir: /var/lib/oprofile
Separate options: library
vmlinux file: none
Image filter: none
Call-graph depth: 25
Buffer size: 1000000
CPU buffer watershed: 256000
CPU buffer size: 32000
 
在安装OProfile的过程中，也可能碰到各种各样的问题，总结如下：
install libiberty.h
checking for libiberty.h... no
checking for cplus_demangle in -liberty... no
configure: error: liberty library not found
安装  binutils-devel，uname -a 确认是x86_64 还是 386
 
如果出现类似，op_cpu_type.c:259:39: error: 'AT_BASE_PLATFORM' undeclared (first use in this function)，如果你是X86_64平台，打上patch屏蔽掉PPC平台的编译；
http://sourceforge.net/p/oprofile/bugs/245/
 
Warning: QT version 3 was requested but not found. No GUI will be built.
Warning: You requested to build with the '--with-kernel' option, but your kernel
headers were not accessible at the given location. Be sure you have run the following
command from within your kernel source tree:
     make headers_install INSTALL_HDR_PATH=<kernel-hdrs-install-dir>
Then pass <kernel-hdrs-install-dir> to oprofile's '--with-kernel' configure option.


If you run 'make' now, only the legacy ocontrol-based profiler will be built.
 
这个原因是因为内部不支持perf event，这时候无法只针对单独的进程进行采样。
 
 
3. GProf http://en.wikipedia.org/wiki/Gprof
GProf用起来很麻烦，编译时候需要加入-pg 选项，而且默认只能针对单线程程序（这个patch可以支持多线程，http://sam.zoy.org/writings/programming/gprof.html），总之极其不便；


 


4. Google Perf Tools https://code.google.com/p/gperftools/?redir=1


参考：https://www.ibm.com/developerworks/cn/linux/l-cn-perf1/


强大免费的工具来了，Gperf 里面包含内存分配器，内存泄露分析器，CPU使用分析器，callgraph也比较精准，用起来简单方便（只要链接lib然后配置一个环境变量就好了），并且自己可以使用代码精确控制profile的配置，具体参考链接左边的几个文章。


 


还有一些其他的分析方法和工具，比如连续做几次pstack看看大部分线程在干吗也可以初步判断可能是哪里出了问题。


 


总之，如果简单的分析一下，那么OProfile是可以胜任的；如果想比较认真仔细的做性能调优，最好使用Google perf tools。

